{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Cross validation\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# Bayes opt\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "# Linear Regression with Lasso\n",
    "from sklearn.linear_model import Lasso\n",
    "# Linear Regression with L2\n",
    "from sklearn.linear_model import Ridge\n",
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# XGBoost\n",
    "import xgboost as xgb\n",
    "# LightGBM\n",
    "import lightgbm as lgbm\n",
    "\n",
    "# Scoring\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Plotting\n",
    "import altair as alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy:1.16.4\n",
      "pandas:0.24.2\n",
      "sklearn:0.22.1\n",
      "xgb:0.90\n",
      "lgbm:2.3.1\n",
      "altair:3.2.0\n"
     ]
    }
   ],
   "source": [
    "# Versions of packages\n",
    "import sklearn \n",
    "import bayes_opt\n",
    "import altair\n",
    "print(\"numpy:\"+np.__version__)\n",
    "print(\"pandas:\"+pd.__version__)\n",
    "print(\"sklearn:\"+sklearn.__version__)\n",
    "# print(bayes_opt.__version__)\n",
    "print(\"xgb:\"+xgb.__version__)\n",
    "print(\"lgbm:\"+lgbm.__version__)\n",
    "print(\"altair:\"+alt.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bayesian-optimization package version 1.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data  = pd.read_csv(\"../data/processed/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>internet</th>\n",
       "      <th>romantic</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>at_home</td>\n",
       "      <td>teacher</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>health</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>16</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GP</td>\n",
       "      <td>M</td>\n",
       "      <td>16</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>services</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  school sex  age address famsize Pstatus  Medu  Fedu      Mjob      Fjob  \\\n",
       "0     GP   F   18       U     GT3       A     4     4   at_home   teacher   \n",
       "1     GP   F   17       U     GT3       T     1     1   at_home     other   \n",
       "2     GP   F   15       U     GT3       T     4     2    health  services   \n",
       "3     GP   F   16       U     GT3       T     3     3     other     other   \n",
       "4     GP   M   16       U     LE3       T     4     3  services     other   \n",
       "\n",
       "   ... internet romantic  famrel  freetime  goout Dalc Walc health absences  \\\n",
       "0  ...       no       no       4         3      4    1    1      3        4   \n",
       "1  ...      yes       no       5         3      3    1    1      3        2   \n",
       "2  ...      yes      yes       3         2      2    1    1      5        0   \n",
       "3  ...       no       no       4         3      2    1    2      5        0   \n",
       "4  ...      yes       no       5         4      2    1    2      5        6   \n",
       "\n",
       "   G3  \n",
       "0  11  \n",
       "1  11  \n",
       "2  14  \n",
       "3  13  \n",
       "4  13  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.drop([\"G3\"], axis = 1)\n",
    "y_train = train_data[\"G3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu',\n",
       "       'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime',\n",
       "       'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery',\n",
       "       'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc',\n",
       "       'Walc', 'health', 'absences'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numerical vs categorical features\n",
    "categorical_features = X_train.loc[:,(\"school\",\"sex\", \"address\", \"famsize\", \"Pstatus\", \"Mjob\", \"Fjob\", \"reason\", \n",
    "                                  \"guardian\",\"schoolsup\", \"famsup\", \"paid\",\"activities\",\"nursery\", \"higher\", \n",
    "                                  \"internet\",\"romantic\")].columns\n",
    "\n",
    "numeric_features = X_train.loc[:,(\"age\", \"Medu\", \"Fedu\", \"traveltime\", \"studytime\", \"failures\", \"famrel\", \n",
    "                                    \"freetime\", \"goout\", \"Dalc\", \"Walc\", \"health\", \"absences\")].columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['school', 'sex', 'address', 'famsize', 'Pstatus', 'Mjob', 'Fjob',\n",
       "       'reason', 'guardian', 'schoolsup', 'famsup', 'paid', 'activities',\n",
       "       'nursery', 'higher', 'internet', 'romantic'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'Medu', 'Fedu', 'traveltime', 'studytime', 'failures', 'famrel',\n",
       "       'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('ohe', OneHotEncoder(drop = \"first\"), categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to dataframe\n",
    "X_train_trans = pd.DataFrame(preprocessor.fit_transform(X_train),\n",
    "                            index = X_train.index,\n",
    "                             columns = (list(numeric_features) +\n",
    "                                       list(preprocessor.named_transformers_['ohe'].get_feature_names(categorical_features))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Model Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmridge_params = {'alpha':(0,100)}\n",
    "\n",
    "def cv_mse_lmridge(alpha):\n",
    "    \"\"\" \n",
    "    Performs cross validation for LM regressor with Ridge regression. To be used for Bayesian optimiser maximizer function.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    alpha : float\n",
    "        L2 regularisation constant\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Cross validation score based on negative mean squared error.\n",
    "        \n",
    "    \"\"\"\n",
    "    estimator = Ridge(alpha)\n",
    "\n",
    "    # Note that scoring is neg_mean_squared_error, which means higher the score, the better the model\n",
    "    return cross_validate(estimator, X_train_trans, y_train, cv = 10, scoring = \"neg_root_mean_squared_error\")[\"test_score\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |   alpha   |\n",
      "-------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-2.736   \u001b[0m | \u001b[0m 41.7    \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m-2.735   \u001b[0m | \u001b[95m 72.03   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-2.77    \u001b[0m | \u001b[0m 0.01144 \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-2.738   \u001b[0m | \u001b[0m 30.23   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-2.745   \u001b[0m | \u001b[0m 14.68   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-2.737   \u001b[0m | \u001b[0m 100.0   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-2.736   \u001b[0m | \u001b[0m 86.29   \u001b[0m |\n",
      "| \u001b[95m 8       \u001b[0m | \u001b[95m-2.735   \u001b[0m | \u001b[95m 58.16   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-2.735   \u001b[0m | \u001b[0m 63.12   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-2.735   \u001b[0m | \u001b[0m 52.72   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-2.735   \u001b[0m | \u001b[0m 72.93   \u001b[0m |\n",
      "| \u001b[95m 12      \u001b[0m | \u001b[95m-2.735   \u001b[0m | \u001b[95m 62.31   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-2.735   \u001b[0m | \u001b[0m 51.52   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-2.736   \u001b[0m | \u001b[0m 78.52   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-2.735   \u001b[0m | \u001b[0m 64.61   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-2.735   \u001b[0m | \u001b[0m 55.51   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-2.735   \u001b[0m | \u001b[0m 66.56   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-2.735   \u001b[0m | \u001b[0m 48.22   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-2.735   \u001b[0m | \u001b[0m 62.92   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-2.735   \u001b[0m | \u001b[0m 70.23   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-2.735   \u001b[0m | \u001b[0m 58.19   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-2.736   \u001b[0m | \u001b[0m 84.42   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-2.735   \u001b[0m | \u001b[0m 57.69   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-2.735   \u001b[0m | \u001b[0m 67.56   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-2.735   \u001b[0m | \u001b[0m 46.71   \u001b[0m |\n",
      "=====================================\n"
     ]
    }
   ],
   "source": [
    "optimizer_lmridge = BayesianOptimization(cv_mse_lmridge, lmridge_params, random_state = 1, verbose = 2)\n",
    "optimizer_lmridge.maximize(n_iter = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': -2.735039423513031, 'params': {'alpha': 60.261882871617445}}"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer_lmridge.max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Model Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmlasso_params = {'alpha':(0.01,100)}\n",
    "\n",
    "def cv_mse_lmlasso(alpha):\n",
    "    \"\"\" \n",
    "    Performs cross validation for LM regressor with Lasso regression. To be used for Bayesian optimiser maximizer function.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    alpha : float\n",
    "        L1 regularisation constant\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Cross validation score based on negative mean squared error.\n",
    "        \n",
    "    \"\"\"\n",
    "    estimator = Lasso(alpha)\n",
    "\n",
    "    # Note that scoring is neg_mean_squared_error, which means higher the score, the better the model\n",
    "    return cross_validate(estimator, X_train_trans, y_train, cv = 10, scoring = \"neg_root_mean_squared_error\")[\"test_score\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |   alpha   |\n",
      "-------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-3.2     \u001b[0m | \u001b[0m 41.71   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-3.2     \u001b[0m | \u001b[0m 72.04   \u001b[0m |\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m-2.731   \u001b[0m | \u001b[95m 0.02144 \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-3.2     \u001b[0m | \u001b[0m 30.24   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-3.2     \u001b[0m | \u001b[0m 14.68   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-3.2     \u001b[0m | \u001b[0m 100.0   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-2.744   \u001b[0m | \u001b[0m 0.01    \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-3.2     \u001b[0m | \u001b[0m 1.969   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-3.2     \u001b[0m | \u001b[0m 56.88   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-3.2     \u001b[0m | \u001b[0m 86.02   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-3.2     \u001b[0m | \u001b[0m 22.46   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-3.2     \u001b[0m | \u001b[0m 49.29   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-3.2     \u001b[0m | \u001b[0m 64.46   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-3.2     \u001b[0m | \u001b[0m 93.01   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-3.2     \u001b[0m | \u001b[0m 79.03   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-3.2     \u001b[0m | \u001b[0m 8.788   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-3.2     \u001b[0m | \u001b[0m 35.97   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-3.2     \u001b[0m | \u001b[0m 18.57   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-3.2     \u001b[0m | \u001b[0m 26.35   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-3.2     \u001b[0m | \u001b[0m 53.08   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-3.2     \u001b[0m | \u001b[0m 45.5    \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-3.2     \u001b[0m | \u001b[0m 60.66   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-3.2     \u001b[0m | \u001b[0m 68.24   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-3.2     \u001b[0m | \u001b[0m 75.53   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-3.2     \u001b[0m | \u001b[0m 82.52   \u001b[0m |\n",
      "=====================================\n"
     ]
    }
   ],
   "source": [
    "optimizer_lmlasso = BayesianOptimization(cv_mse_lmlasso, lmlasso_params, random_state = 1)\n",
    "optimizer_lmlasso.maximize(n_iter = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SKLearn Random Forest\n",
    "rf_params = {'n_estimators':(10,150), 'max_depth':(10,200), 'max_features':(2, 30)}\n",
    "\n",
    "def cv_mse_rf(n_estimators,max_depth, max_features):\n",
    "    \"\"\" \n",
    "    Performs cross validation for Random Forest Regressor. To be used for Bayesian optimiser maximizer function.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_estimators : float\n",
    "        Number of estimators for random forest\n",
    "    max_depth : float\n",
    "        Max depth of trees in random forest\n",
    "    max_features : float\n",
    "        Max number of features in random forest\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Cross validation score based on negative mean squared error.\n",
    "        \n",
    "    \"\"\"\n",
    "    # Convert chosen hyperparams to discrete integer\n",
    "    max_depth = int(max_depth)\n",
    "    max_features = int(max_features)\n",
    "    n_estimators = int(n_estimators)\n",
    "    \n",
    "    estimator = RandomForestRegressor(n_estimators = n_estimators, max_depth = max_depth, max_features = max_features)\n",
    "\n",
    "    # Note that scoring is neg_mean_squared_error, which means higher the score, the better the model\n",
    "    return cross_validate(estimator, X_train_trans, y_train, cv = 10, scoring = \"neg_root_mean_squared_error\")[\"test_score\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | max_depth | max_fe... | n_esti... |\n",
      "-------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-2.9     \u001b[0m | \u001b[0m 89.23   \u001b[0m | \u001b[0m 22.17   \u001b[0m | \u001b[0m 10.02   \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m-2.717   \u001b[0m | \u001b[95m 67.44   \u001b[0m | \u001b[95m 6.109   \u001b[0m | \u001b[95m 22.93   \u001b[0m |\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m-2.65    \u001b[0m | \u001b[95m 45.39   \u001b[0m | \u001b[95m 11.68   \u001b[0m | \u001b[95m 65.55   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-2.672   \u001b[0m | \u001b[0m 112.4   \u001b[0m | \u001b[0m 13.74   \u001b[0m | \u001b[0m 105.9   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-2.775   \u001b[0m | \u001b[0m 48.85   \u001b[0m | \u001b[0m 26.59   \u001b[0m | \u001b[0m 13.83   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-2.705   \u001b[0m | \u001b[0m 200.0   \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 150.0   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-2.729   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 150.0   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-2.914   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 10.0    \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-2.712   \u001b[0m | \u001b[0m 83.69   \u001b[0m | \u001b[0m 30.0    \u001b[0m | \u001b[0m 150.0   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-2.728   \u001b[0m | \u001b[0m 200.0   \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 55.75   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-2.725   \u001b[0m | \u001b[0m 200.0   \u001b[0m | \u001b[0m 30.0    \u001b[0m | \u001b[0m 109.0   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-2.726   \u001b[0m | \u001b[0m 80.2    \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 150.0   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-2.699   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 30.0    \u001b[0m | \u001b[0m 115.2   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-2.705   \u001b[0m | \u001b[0m 171.7   \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 102.7   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-2.707   \u001b[0m | \u001b[0m 82.37   \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 77.79   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-2.692   \u001b[0m | \u001b[0m 152.4   \u001b[0m | \u001b[0m 30.0    \u001b[0m | \u001b[0m 150.0   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-2.931   \u001b[0m | \u001b[0m 200.0   \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 10.0    \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-2.716   \u001b[0m | \u001b[0m 61.46   \u001b[0m | \u001b[0m 30.0    \u001b[0m | \u001b[0m 69.5    \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-2.751   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 91.53   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-2.678   \u001b[0m | \u001b[0m 134.3   \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 150.0   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-2.694   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 30.0    \u001b[0m | \u001b[0m 150.0   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-2.735   \u001b[0m | \u001b[0m 14.15   \u001b[0m | \u001b[0m 30.0    \u001b[0m | \u001b[0m 58.04   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-2.74    \u001b[0m | \u001b[0m 46.02   \u001b[0m | \u001b[0m 2.259   \u001b[0m | \u001b[0m 47.72   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-2.678   \u001b[0m | \u001b[0m 49.03   \u001b[0m | \u001b[0m 15.3    \u001b[0m | \u001b[0m 112.5   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-2.713   \u001b[0m | \u001b[0m 200.0   \u001b[0m | \u001b[0m 30.0    \u001b[0m | \u001b[0m 150.0   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-2.732   \u001b[0m | \u001b[0m 200.0   \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 105.3   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m-2.741   \u001b[0m | \u001b[0m 143.8   \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 59.44   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m-2.729   \u001b[0m | \u001b[0m 200.0   \u001b[0m | \u001b[0m 30.0    \u001b[0m | \u001b[0m 55.32   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m-2.697   \u001b[0m | \u001b[0m 32.87   \u001b[0m | \u001b[0m 26.56   \u001b[0m | \u001b[0m 85.5    \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m-2.676   \u001b[0m | \u001b[0m 46.24   \u001b[0m | \u001b[0m 11.33   \u001b[0m | \u001b[0m 62.81   \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m-2.737   \u001b[0m | \u001b[0m 144.9   \u001b[0m | \u001b[0m 29.79   \u001b[0m | \u001b[0m 83.08   \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m-2.736   \u001b[0m | \u001b[0m 51.72   \u001b[0m | \u001b[0m 2.014   \u001b[0m | \u001b[0m 89.4    \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m-2.887   \u001b[0m | \u001b[0m 141.6   \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 10.0    \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m-2.716   \u001b[0m | \u001b[0m 43.65   \u001b[0m | \u001b[0m 29.09   \u001b[0m | \u001b[0m 148.8   \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m-2.733   \u001b[0m | \u001b[0m 82.94   \u001b[0m | \u001b[0m 29.52   \u001b[0m | \u001b[0m 107.6   \u001b[0m |\n",
      "=============================================================\n"
     ]
    }
   ],
   "source": [
    "optimizer_rf = BayesianOptimization(cv_mse_rf, rf_params, random_state = 1)\n",
    "optimizer_rf.maximize(n_iter = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost Regressor\n",
    "xgb_params = {'n_estimators':(10, 150), 'max_depth':(10, 200), 'learning_rate':(0.001, 1),\n",
    "              'subsample':(0, 1), 'gamma':(0, 50), 'reg_alpha':(0, 100), 'reg_lambda':(0, 100)}\n",
    "\n",
    "def cv_mse_xgb(n_estimators, max_depth, learning_rate, subsample, gamma, reg_alpha, reg_lambda):\n",
    "    \"\"\" \n",
    "    Performs cross validation for Random Forest Regressor. To be used for Bayesian optimiser maximizer function.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_estimators : float\n",
    "        Number of estimators\n",
    "    max_depth : float\n",
    "        Max depth of trees\n",
    "    learning_rate : float\n",
    "        Learning rate\n",
    "    subsample : float\n",
    "        Subsample ratio of training instances \n",
    "    gamma : float\n",
    "        Min loss reduction to make further partition on leaf node   \n",
    "    reg_alpha : float\n",
    "        L1 regularisation\n",
    "    reg_lambda : float\n",
    "        L2 regularisation\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Cross validation score based on negative mean squared error.\n",
    "        \n",
    "    \"\"\"\n",
    "    # Convert chosen hyperparams to discrete integer\n",
    "    max_depth = int(max_depth)\n",
    "    n_estimators = int(n_estimators)\n",
    "    \n",
    "    estimator = xgb.XGBRegressor(objective='reg:squarederror',\n",
    "                                 n_estimators = n_estimators, \n",
    "                                 max_depth = max_depth, \n",
    "                                 learning_rate = learning_rate, \n",
    "                                 subsample = subsample,\n",
    "                                 gamma = gamma, \n",
    "                                 reg_alpha = reg_alpha, \n",
    "                                 reg_lambda = reg_lambda)\n",
    "\n",
    "    # Note that scoring is neg_mean_squared_error, which means higher the score, the better the model\n",
    "    return cross_validate(estimator, X_train_trans, y_train, cv = 10, scoring = \"neg_root_mean_squared_error\")[\"test_score\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |   gamma   | learni... | max_depth | n_esti... | reg_alpha | reg_la... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-2.909   \u001b[0m | \u001b[0m 20.85   \u001b[0m | \u001b[0m 0.7206  \u001b[0m | \u001b[0m 10.02   \u001b[0m | \u001b[0m 52.33   \u001b[0m | \u001b[0m 14.68   \u001b[0m | \u001b[0m 9.234   \u001b[0m | \u001b[0m 0.1863  \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m-2.729   \u001b[0m | \u001b[95m 17.28   \u001b[0m | \u001b[95m 0.3974  \u001b[0m | \u001b[95m 112.4   \u001b[0m | \u001b[95m 68.69   \u001b[0m | \u001b[95m 68.52   \u001b[0m | \u001b[95m 20.45   \u001b[0m | \u001b[95m 0.8781  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-2.953   \u001b[0m | \u001b[0m 1.369   \u001b[0m | \u001b[0m 0.6708  \u001b[0m | \u001b[0m 89.29   \u001b[0m | \u001b[0m 88.22   \u001b[0m | \u001b[0m 14.04   \u001b[0m | \u001b[0m 19.81   \u001b[0m | \u001b[0m 0.8007  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-4.358   \u001b[0m | \u001b[0m 48.41   \u001b[0m | \u001b[0m 0.3141  \u001b[0m | \u001b[0m 141.5   \u001b[0m | \u001b[0m 132.7   \u001b[0m | \u001b[0m 89.46   \u001b[0m | \u001b[0m 8.504   \u001b[0m | \u001b[0m 0.03905 \u001b[0m |\n",
      "| \u001b[95m 5       \u001b[0m | \u001b[95m-2.728   \u001b[0m | \u001b[95m 8.492   \u001b[0m | \u001b[95m 0.8783  \u001b[0m | \u001b[95m 28.69   \u001b[0m | \u001b[95m 68.96   \u001b[0m | \u001b[95m 95.79   \u001b[0m | \u001b[95m 53.32   \u001b[0m | \u001b[95m 0.6919  \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-11.71   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 123.6   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 41.37   \u001b[0m | \u001b[0m 100.0   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-2.818   \u001b[0m | \u001b[0m 12.94   \u001b[0m | \u001b[0m 0.6685  \u001b[0m | \u001b[0m 70.0    \u001b[0m | \u001b[0m 76.44   \u001b[0m | \u001b[0m 57.11   \u001b[0m | \u001b[0m 20.76   \u001b[0m | \u001b[0m 0.7061  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-2.734   \u001b[0m | \u001b[0m 13.16   \u001b[0m | \u001b[0m 0.8508  \u001b[0m | \u001b[0m 20.15   \u001b[0m | \u001b[0m 67.28   \u001b[0m | \u001b[0m 57.52   \u001b[0m | \u001b[0m 29.46   \u001b[0m | \u001b[0m 0.4754  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-2.78    \u001b[0m | \u001b[0m 24.43   \u001b[0m | \u001b[0m 0.6934  \u001b[0m | \u001b[0m 45.03   \u001b[0m | \u001b[0m 60.06   \u001b[0m | \u001b[0m 95.56   \u001b[0m | \u001b[0m 13.44   \u001b[0m | \u001b[0m 0.6331  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-10.81   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 33.73   \u001b[0m | \u001b[0m 101.9   \u001b[0m | \u001b[0m 90.12   \u001b[0m | \u001b[0m 19.04   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-2.755   \u001b[0m | \u001b[0m 16.39   \u001b[0m | \u001b[0m 0.4522  \u001b[0m | \u001b[0m 103.8   \u001b[0m | \u001b[0m 70.26   \u001b[0m | \u001b[0m 66.16   \u001b[0m | \u001b[0m 20.5    \u001b[0m | \u001b[0m 0.8434  \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-2.768   \u001b[0m | \u001b[0m 14.16   \u001b[0m | \u001b[0m 0.9726  \u001b[0m | \u001b[0m 28.05   \u001b[0m | \u001b[0m 61.89   \u001b[0m | \u001b[0m 81.61   \u001b[0m | \u001b[0m 42.92   \u001b[0m | \u001b[0m 0.5536  \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-2.782   \u001b[0m | \u001b[0m 21.22   \u001b[0m | \u001b[0m 0.9345  \u001b[0m | \u001b[0m 38.93   \u001b[0m | \u001b[0m 57.45   \u001b[0m | \u001b[0m 72.88   \u001b[0m | \u001b[0m 24.95   \u001b[0m | \u001b[0m 0.497   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-2.865   \u001b[0m | \u001b[0m 21.46   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 41.39   \u001b[0m | \u001b[0m 53.84   \u001b[0m | \u001b[0m 95.36   \u001b[0m | \u001b[0m 36.5    \u001b[0m | \u001b[0m 0.5686  \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-2.764   \u001b[0m | \u001b[0m 22.57   \u001b[0m | \u001b[0m 0.8525  \u001b[0m | \u001b[0m 65.36   \u001b[0m | \u001b[0m 58.33   \u001b[0m | \u001b[0m 76.95   \u001b[0m | \u001b[0m 22.3    \u001b[0m | \u001b[0m 0.6097  \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-2.75    \u001b[0m | \u001b[0m 16.1    \u001b[0m | \u001b[0m 0.9902  \u001b[0m | \u001b[0m 45.64   \u001b[0m | \u001b[0m 60.63   \u001b[0m | \u001b[0m 48.45   \u001b[0m | \u001b[0m 31.84   \u001b[0m | \u001b[0m 0.4634  \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-2.776   \u001b[0m | \u001b[0m 21.84   \u001b[0m | \u001b[0m 0.9292  \u001b[0m | \u001b[0m 22.06   \u001b[0m | \u001b[0m 50.84   \u001b[0m | \u001b[0m 42.24   \u001b[0m | \u001b[0m 21.15   \u001b[0m | \u001b[0m 0.2912  \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-3.258   \u001b[0m | \u001b[0m 22.83   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 23.96   \u001b[0m | \u001b[0m 52.14   \u001b[0m | \u001b[0m 56.27   \u001b[0m | \u001b[0m 47.48   \u001b[0m | \u001b[0m 0.09118 \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-2.741   \u001b[0m | \u001b[0m 24.08   \u001b[0m | \u001b[0m 0.8155  \u001b[0m | \u001b[0m 60.74   \u001b[0m | \u001b[0m 55.46   \u001b[0m | \u001b[0m 50.59   \u001b[0m | \u001b[0m 8.072   \u001b[0m | \u001b[0m 0.5181  \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-2.83    \u001b[0m | \u001b[0m 16.32   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 83.08   \u001b[0m | \u001b[0m 62.32   \u001b[0m | \u001b[0m 36.67   \u001b[0m | \u001b[0m 23.89   \u001b[0m | \u001b[0m 0.5888  \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-2.878   \u001b[0m | \u001b[0m 32.34   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 49.38   \u001b[0m | \u001b[0m 37.77   \u001b[0m | \u001b[0m 83.5    \u001b[0m | \u001b[0m 7.391   \u001b[0m | \u001b[0m 0.5379  \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-2.75    \u001b[0m | \u001b[0m 8.608   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 20.31   \u001b[0m | \u001b[0m 46.65   \u001b[0m | \u001b[0m 96.7    \u001b[0m | \u001b[0m 63.04   \u001b[0m | \u001b[0m 0.7923  \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-3.038   \u001b[0m | \u001b[0m 13.05   \u001b[0m | \u001b[0m 0.927   \u001b[0m | \u001b[0m 48.01   \u001b[0m | \u001b[0m 69.33   \u001b[0m | \u001b[0m 21.0    \u001b[0m | \u001b[0m 12.46   \u001b[0m | \u001b[0m 0.5032  \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-3.823   \u001b[0m | \u001b[0m 22.74   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 39.28   \u001b[0m | \u001b[0m 62.77   \u001b[0m | \u001b[0m 90.34   \u001b[0m | \u001b[0m 73.83   \u001b[0m | \u001b[0m 0.06012 \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-2.799   \u001b[0m | \u001b[0m 5.085   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 18.36   \u001b[0m | \u001b[0m 36.87   \u001b[0m | \u001b[0m 84.21   \u001b[0m | \u001b[0m 28.75   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-2.772   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 50.82   \u001b[0m | \u001b[0m 37.9    \u001b[0m | \u001b[0m 61.61   \u001b[0m | \u001b[0m 17.92   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m-11.79   \u001b[0m | \u001b[0m 3.284   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 87.39   \u001b[0m | \u001b[0m 46.82   \u001b[0m | \u001b[0m 63.87   \u001b[0m | \u001b[0m 3.492   \u001b[0m | \u001b[0m 0.0     \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m-2.796   \u001b[0m | \u001b[0m 15.78   \u001b[0m | \u001b[0m 0.833   \u001b[0m | \u001b[0m 42.26   \u001b[0m | \u001b[0m 49.34   \u001b[0m | \u001b[0m 55.3    \u001b[0m | \u001b[0m 16.25   \u001b[0m | \u001b[0m 0.9345  \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m-2.78    \u001b[0m | \u001b[0m 27.21   \u001b[0m | \u001b[0m 0.7425  \u001b[0m | \u001b[0m 57.46   \u001b[0m | \u001b[0m 64.74   \u001b[0m | \u001b[0m 58.16   \u001b[0m | \u001b[0m 22.66   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m-2.821   \u001b[0m | \u001b[0m 5.154   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 35.57   \u001b[0m | \u001b[0m 44.95   \u001b[0m | \u001b[0m 69.14   \u001b[0m | \u001b[0m 30.79   \u001b[0m | \u001b[0m 0.8421  \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m-2.785   \u001b[0m | \u001b[0m 19.99   \u001b[0m | \u001b[0m 0.7755  \u001b[0m | \u001b[0m 62.61   \u001b[0m | \u001b[0m 68.3    \u001b[0m | \u001b[0m 38.14   \u001b[0m | \u001b[0m 20.44   \u001b[0m | \u001b[0m 0.6785  \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m-2.805   \u001b[0m | \u001b[0m 14.17   \u001b[0m | \u001b[0m 0.703   \u001b[0m | \u001b[0m 43.31   \u001b[0m | \u001b[0m 42.12   \u001b[0m | \u001b[0m 84.87   \u001b[0m | \u001b[0m 19.43   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m-2.867   \u001b[0m | \u001b[0m 2.698   \u001b[0m | \u001b[0m 0.9971  \u001b[0m | \u001b[0m 27.85   \u001b[0m | \u001b[0m 48.88   \u001b[0m | \u001b[0m 94.37   \u001b[0m | \u001b[0m 43.95   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m-11.28   \u001b[0m | \u001b[0m 36.29   \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 52.51   \u001b[0m | \u001b[0m 52.4    \u001b[0m | \u001b[0m 82.96   \u001b[0m | \u001b[0m 24.09   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m-2.756   \u001b[0m | \u001b[0m 20.34   \u001b[0m | \u001b[0m 0.8321  \u001b[0m | \u001b[0m 57.12   \u001b[0m | \u001b[0m 61.5    \u001b[0m | \u001b[0m 49.58   \u001b[0m | \u001b[0m 18.98   \u001b[0m | \u001b[0m 0.6565  \u001b[0m |\n",
      "=============================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Warnings due to some current issue with xgboost incompatibility with pandas deprecation\n",
    "# Fix will be for upcoming xgboost version 1.0.0, but latest version is only 0.90\n",
    "# See https://github.com/dmlc/xgboost/issues/4300\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Fixed random state due to xgboost hyper param combination throwing a result for NaN\n",
    "optimizer_xgb = BayesianOptimization(cv_mse_xgb, xgb_params, random_state = 1)\n",
    "optimizer_xgb.maximize(n_iter = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM\n",
    "lgbm_params = {'n_estimators':(10, 150), 'max_depth':(10, 200), 'learning_rate':(0.001, 1),\n",
    "               'reg_alpha':(0, 100), 'reg_lambda':(0, 100)}\n",
    "\n",
    "def cv_mse_lgbm(n_estimators, max_depth, learning_rate, reg_alpha, reg_lambda):\n",
    "    \"\"\" \n",
    "    Performs cross validation for Random Forest Regressor. To be used for Bayesian optimiser maximizer function.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_estimators : float\n",
    "        Number of estimators\n",
    "    max_depth : float\n",
    "        Max depth of trees\n",
    "    learning_rate : float\n",
    "        Learning rate\n",
    "    reg_alpha : float\n",
    "        L1 regularisation\n",
    "    reg_lambda : float\n",
    "        L2 regularisation\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Cross validation score based on negative mean squared error.\n",
    "        \n",
    "    \"\"\"\n",
    "    # Convert chosen hyperparams to discrete integer\n",
    "    max_depth = int(max_depth)\n",
    "    n_estimators = int(n_estimators)\n",
    "    \n",
    "    estimator = lgbm.LGBMRegressor(n_estimators = n_estimators, \n",
    "                                 max_depth = max_depth, \n",
    "                                 learning_rate = learning_rate, \n",
    "                                 reg_alpha = reg_alpha, \n",
    "                                 reg_lambda = reg_lambda)\n",
    "    \n",
    "    # Note that scoring is neg_mean_squared_error, which means higher the score, the better the model\n",
    "    return cross_validate(estimator, X_train_trans, y_train, cv = 10, scoring = \"neg_root_mean_squared_error\")[\"test_score\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | learni... | max_depth | n_esti... | reg_alpha | reg_la... |\n",
      "-------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-2.727   \u001b[0m | \u001b[0m 0.4176  \u001b[0m | \u001b[0m 146.9   \u001b[0m | \u001b[0m 10.02   \u001b[0m | \u001b[0m 30.23   \u001b[0m | \u001b[0m 14.68   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-2.749   \u001b[0m | \u001b[0m 0.09325 \u001b[0m | \u001b[0m 45.39   \u001b[0m | \u001b[0m 58.38   \u001b[0m | \u001b[0m 39.68   \u001b[0m | \u001b[0m 53.88   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-2.809   \u001b[0m | \u001b[0m 0.4198  \u001b[0m | \u001b[0m 140.2   \u001b[0m | \u001b[0m 38.62   \u001b[0m | \u001b[0m 87.81   \u001b[0m | \u001b[0m 2.739   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-2.802   \u001b[0m | \u001b[0m 0.6708  \u001b[0m | \u001b[0m 89.29   \u001b[0m | \u001b[0m 88.22   \u001b[0m | \u001b[0m 14.04   \u001b[0m | \u001b[0m 19.81   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-2.79    \u001b[0m | \u001b[0m 0.8009  \u001b[0m | \u001b[0m 194.0   \u001b[0m | \u001b[0m 53.88   \u001b[0m | \u001b[0m 69.23   \u001b[0m | \u001b[0m 87.64   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-2.769   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 4.931e-1\u001b[0m | \u001b[0m 100.0   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-3.167   \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 150.0   \u001b[0m | \u001b[0m 100.0   \u001b[0m | \u001b[0m 100.0   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-3.19    \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-3.136   \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 200.0   \u001b[0m | \u001b[0m 150.0   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 100.0   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-2.823   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 92.09   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 100.0   \u001b[0m | \u001b[0m 100.0   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-3.195   \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 200.0   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 100.0   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-2.831   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 200.0   \u001b[0m | \u001b[0m 150.0   \u001b[0m | \u001b[0m 100.0   \u001b[0m | \u001b[0m 0.0     \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-3.003   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 150.0   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 100.0   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-3.554   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 200.0   \u001b[0m | \u001b[0m 81.25   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-2.823   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 153.6   \u001b[0m | \u001b[0m 150.0   \u001b[0m | \u001b[0m 100.0   \u001b[0m | \u001b[0m 100.0   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-3.181   \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 93.23   \u001b[0m | \u001b[0m 42.7    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 100.0   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-2.831   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 150.0   \u001b[0m | \u001b[0m 100.0   \u001b[0m | \u001b[0m 0.0     \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-3.076   \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 150.0   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-2.84    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 100.0   \u001b[0m | \u001b[0m 30.54   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-2.827   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 200.0   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 100.0   \u001b[0m | \u001b[0m 52.33   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-3.137   \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 102.1   \u001b[0m | \u001b[0m 150.0   \u001b[0m | \u001b[0m 100.0   \u001b[0m | \u001b[0m 0.0     \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-3.167   \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 200.0   \u001b[0m | \u001b[0m 150.0   \u001b[0m | \u001b[0m 100.0   \u001b[0m | \u001b[0m 100.0   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-2.823   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 100.0   \u001b[0m | \u001b[0m 100.0   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-2.758   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 105.7   \u001b[0m | \u001b[0m 150.0   \u001b[0m | \u001b[0m 32.27   \u001b[0m | \u001b[0m 100.0   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-2.832   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 120.7   \u001b[0m | \u001b[0m 84.54   \u001b[0m | \u001b[0m 100.0   \u001b[0m | \u001b[0m 74.57   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-2.827   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 83.46   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 60.33   \u001b[0m | \u001b[0m 0.0     \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m-2.831   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 79.22   \u001b[0m | \u001b[0m 100.0   \u001b[0m | \u001b[0m 0.0     \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m-2.781   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 140.1   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 64.37   \u001b[0m | \u001b[0m 59.91   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m-2.823   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 200.0   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 100.0   \u001b[0m | \u001b[0m 100.0   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m-2.765   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 146.5   \u001b[0m | \u001b[0m 150.0   \u001b[0m | \u001b[0m 49.76   \u001b[0m | \u001b[0m 53.35   \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m-2.82    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 200.0   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 69.18   \u001b[0m | \u001b[0m 0.0     \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m-2.741   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 66.47   \u001b[0m | \u001b[0m 37.62   \u001b[0m | \u001b[0m 100.0   \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m-2.792   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 107.4   \u001b[0m | \u001b[0m 50.16   \u001b[0m | \u001b[0m 39.15   \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m-2.737   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 47.19   \u001b[0m | \u001b[0m 100.0   \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m-2.767   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 143.1   \u001b[0m | \u001b[0m 110.9   \u001b[0m | \u001b[0m 56.52   \u001b[0m | \u001b[0m 100.0   \u001b[0m |\n",
      "=====================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Fixed random state due to xgboost hyper param combination throwing a result for NaN\n",
    "optimizer_lgbm = BayesianOptimization(cv_mse_lgbm, lgbm_params, random_state = 1)\n",
    "optimizer_lgbm.maximize(n_iter = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cv_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lm_lasso</th>\n",
       "      <td>2.731073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lm_ridge</th>\n",
       "      <td>2.735046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>randomforest</th>\n",
       "      <td>2.649802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>2.727777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgbm</th>\n",
       "      <td>2.726576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              cv_score\n",
       "lm_lasso      2.731073\n",
       "lm_ridge      2.735046\n",
       "randomforest  2.649802\n",
       "xgb           2.727777\n",
       "lgbm          2.726576"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the best models\n",
    "cv_rmse = [-optimizer_lmlasso.max['target'], \n",
    "             -optimizer_lmridge.max['target'], \n",
    "             -optimizer_rf.max['target'],\n",
    "             -optimizer_xgb.max['target'],\n",
    "             -optimizer_lgbm.max['target']]\n",
    "\n",
    "models = [\"lm_lasso\", \"lm_ridge\", \"randomforest\", \"xgb\", \"lgbm\"]\n",
    "\n",
    "cv_df = pd.DataFrame(cv_rmse, index = models, columns = [\"cv_score\"])\n",
    "\n",
    "# Output to csv\n",
    "cv_df.to_csv(\"../data/output/cv_results.csv\")\n",
    "\n",
    "cv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusting discrete hyperparam for certain models\n",
    "rf_hyperparam = optimizer_rf.max['params']\n",
    "rf_hyperparam['max_depth'] = int(rf_hyperparam['max_depth'])\n",
    "rf_hyperparam['max_features'] = int(rf_hyperparam['max_features'])\n",
    "rf_hyperparam['n_estimators'] = int(rf_hyperparam['n_estimators'])\n",
    "\n",
    "xgb_hyperparam = optimizer_xgb.max['params']\n",
    "xgb_hyperparam['max_depth'] = int(xgb_hyperparam['max_depth'])\n",
    "xgb_hyperparam['n_estimators'] = int(xgb_hyperparam['n_estimators'])\n",
    "\n",
    "lgbm_hyperparam = optimizer_lgbm.max['params']\n",
    "lgbm_hyperparam['max_depth'] = int(lgbm_hyperparam['max_depth'])\n",
    "lgbm_hyperparam['n_estimators'] = int(lgbm_hyperparam['n_estimators'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store as Series for writing to csv\n",
    "lmlasso_hyperparam_series = pd.Series(optimizer_lmlasso.max['params'])\n",
    "\n",
    "lmridge_hyperparam_series = pd.Series(optimizer_lmridge.max['params'])\n",
    "\n",
    "rf_hyperparam_series = pd.Series(rf_hyperparam)\n",
    "\n",
    "xgb_hyperparam_series = pd.Series(xgb_hyperparam)\n",
    "\n",
    "lgbm_hyperparam_series = pd.Series(lgbm_hyperparam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output model params to csv\n",
    "lmlasso_hyperparam_series.to_csv(\"../data/output/lmlasso_hyperparam.csv\", header = False)\n",
    "lmridge_hyperparam_series.to_csv(\"../data/output/lmridge_hyperparam.csv\", header = False)\n",
    "rf_hyperparam_series.to_csv(\"../data/output/rf_hyperparam.csv\", header = False)\n",
    "xgb_hyperparam_series.to_csv(\"../data/output/xgb_hyperparam.csv\", header = False)\n",
    "lgbm_hyperparam_series.to_csv(\"../data/output/lgbm_hyperparam.csv\", header = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read hyperparams from stored output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Read in stored hyperparams. To be used when restart from offline\n",
    "lmlasso_hyperparam_series = pd.Series.from_csv(\"../data/output/lmlasso_hyperparam.csv\")\n",
    "\n",
    "lmridge_hyperparam_series = pd.Series.from_csv(\"../data/output/lmridge_hyperparam.csv\")\n",
    "\n",
    "rf_hyperparam_series = pd.Series.from_csv(\"../data/output/rf_hyperparam.csv\")\n",
    "\n",
    "xgb_hyperparam_series = pd.Series.from_csv(\"../data/output/xgb_hyperparam.csv\")\n",
    "\n",
    "lgbm_hyperparam_series = pd.Series.from_csv(\"../data/output/lgbm_hyperparam.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.021436337986315217}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lmlasso_hyperparam = dict()\n",
    "for i in lmlasso_hyperparam_series.index:\n",
    "    lmlasso_hyperparam[i] = lmlasso_hyperparam_series[i]\n",
    "\n",
    "lmlasso_hyperparam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 62.310253248725566}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lmridge_hyperparam = dict()\n",
    "for i in lmridge_hyperparam_series.index:\n",
    "    lmridge_hyperparam[i] = lmridge_hyperparam_series[i]\n",
    "\n",
    "lmridge_hyperparam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 45, 'max_features': 11, 'n_estimators': 65}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_hyperparam = dict()\n",
    "for i in rf_hyperparam_series.index:\n",
    "    rf_hyperparam[i] = rf_hyperparam_series[i]\n",
    "\n",
    "rf_hyperparam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gamma': 8.491520978228445,\n",
       " 'learning_rate': 0.8782643609259837,\n",
       " 'max_depth': 28,\n",
       " 'n_estimators': 68,\n",
       " 'reg_alpha': 95.7889530150502,\n",
       " 'reg_lambda': 53.316528497301704,\n",
       " 'subsample': 0.6918771139504734}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_hyperparam = dict()\n",
    "for i in xgb_hyperparam_series.index:\n",
    "    \n",
    "    # For integer hyperparams\n",
    "    if i == \"max_depth\" or i == \"n_estimators\" or i == \"max_features\":\n",
    "        xgb_hyperparam[i] = int(xgb_hyperparam_series[i])\n",
    "    # For float hyperparams\n",
    "    else:\n",
    "        xgb_hyperparam[i] = xgb_hyperparam_series[i]\n",
    "\n",
    "xgb_hyperparam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.41760498269787133,\n",
       " 'max_depth': 146,\n",
       " 'n_estimators': 10,\n",
       " 'reg_alpha': 30.233257263183976,\n",
       " 'reg_lambda': 14.675589081711305}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_hyperparam = dict()\n",
    "for i in lgbm_hyperparam_series.index:\n",
    "    \n",
    "    # For integer hyperparams\n",
    "    if i == \"max_depth\" or i == \"n_estimators\" or i == \"max_features\":\n",
    "        lgbm_hyperparam[i] = int(lgbm_hyperparam_series[i])\n",
    "    # For float hyperparams\n",
    "    else:\n",
    "        lgbm_hyperparam[i] = lgbm_hyperparam_series[i]\n",
    "\n",
    "lgbm_hyperparam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"lm_lasso\", \"lm_ridge\", \"randomforest\", \"xgb\", \"lgbm\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create models and score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.021436337986315217, copy_X=True, fit_intercept=True,\n",
       "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "      random_state=1, selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lasso = Lasso(random_state = 1).set_params(**lmlasso_hyperparam)\n",
    "best_lasso.fit(X_train_trans, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=62.310253248725566, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "      normalize=False, random_state=1, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_ridge = Ridge(random_state = 1).set_params(**lmridge_hyperparam)\n",
    "best_ridge.fit(X_train_trans, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=45, max_features=11, max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=65, n_jobs=None, oob_score=False,\n",
       "                      random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rf = RandomForestRegressor(random_state = 1).set_params(**rf_hyperparam)\n",
    "best_rf.fit(X_train_trans, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:39:35] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=8.491520978228445,\n",
       "             importance_type='gain', learning_rate=0.8782643609259837,\n",
       "             max_delta_step=0, max_depth=28, min_child_weight=1, missing=None,\n",
       "             n_estimators=68, n_jobs=1, nthread=None, objective='reg:linear',\n",
       "             random_state=1, reg_alpha=95.7889530150502,\n",
       "             reg_lambda=53.316528497301704, scale_pos_weight=1, seed=None,\n",
       "             silent=None, subsample=0.6918771139504734, verbosity=1)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_xgb = xgb.XGBRegressor(random_state = 1).set_params(**xgb_hyperparam)\n",
    "best_xgb.fit(X_train_trans, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "              importance_type='split', learning_rate=0.41760498269787133,\n",
       "              max_depth=146, min_child_samples=20, min_child_weight=0.001,\n",
       "              min_split_gain=0.0, n_estimators=10, n_jobs=-1, num_leaves=31,\n",
       "              objective=None, random_state=1, reg_alpha=30.233257263183976,\n",
       "              reg_lambda=14.675589081711305, silent=True, subsample=1.0,\n",
       "              subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lgbm = lgbm.LGBMRegressor(random_state = 1).set_params(**lgbm_hyperparam)\n",
    "best_lgbm.fit(X_train_trans, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set\n",
    "test_data  = pd.read_csv(\"../data/processed/test.csv\")\n",
    "\n",
    "X_test = test_data.drop([\"G3\"], axis = 1)\n",
    "y_test = test_data[\"G3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to dataframe\n",
    "X_test_trans = pd.DataFrame(preprocessor.fit_transform(X_test),\n",
    "                            index = X_test.index,\n",
    "                             columns = (list(numeric_features) +\n",
    "                                       list(preprocessor.named_transformers_['ohe'].get_feature_names(categorical_features))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Data Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>randomforest</th>\n",
       "      <td>2.446102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>2.472826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lm_ridge</th>\n",
       "      <td>2.481333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lm_lasso</th>\n",
       "      <td>2.492114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgbm</th>\n",
       "      <td>2.577540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              test_rmse\n",
       "randomforest   2.446102\n",
       "xgb            2.472826\n",
       "lm_ridge       2.481333\n",
       "lm_lasso       2.492114\n",
       "lgbm           2.577540"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_rmse = []\n",
    "test_rmse.append(np.sqrt(mean_squared_error(y_test, best_lasso.predict(X_test_trans))))\n",
    "test_rmse.append(np.sqrt(mean_squared_error(y_test, best_ridge.predict(X_test_trans))))\n",
    "test_rmse.append(np.sqrt(mean_squared_error(y_test, best_rf.predict(X_test_trans))))\n",
    "test_rmse.append(np.sqrt(mean_squared_error(y_test, best_xgb.predict(X_test_trans))))\n",
    "test_rmse.append(np.sqrt(mean_squared_error(y_test, best_lgbm.predict(X_test_trans))))\n",
    "\n",
    "# Convert to Dataframe\n",
    "test_rmse = pd.DataFrame(test_rmse, index= models, columns = [\"test_rmse\"])\n",
    "test_rmse = test_rmse.sort_values(by=\"test_rmse\", ascending = True)\n",
    "test_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary of all models\n",
    "models_dict = dict()\n",
    "models_dict[\"lm_lasso\"] = best_lasso\n",
    "models_dict[\"lm_ridge\"] = best_ridge\n",
    "models_dict[\"randomforest\"] = best_rf\n",
    "models_dict[\"xgb\"] = best_xgb\n",
    "models_dict[\"lgbm\"] = best_lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = models_dict[list(test_rmse.head(1).index)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              test_rmse\n",
      "randomforest   2.446102\n"
     ]
    }
   ],
   "source": [
    "# Best model\n",
    "print(test_rmse.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If model is linear regression model, use \"coef_\" to extract weights\n",
    "if best_model ==best_lasso or best_model == best_ridge:\n",
    "    feat_importance = pd.DataFrame(best_model.coef_, index = X_train_trans.columns, columns = [\"Importance\"])\n",
    "\n",
    "# If model is tree based, use \"feature_importances\" to extract importances    \n",
    "else: \n",
    "    feat_importance = pd.DataFrame(best_model.feature_importances_, index = X_train_trans.columns, columns = [\"Importance\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_importance = feat_importance.sort_values(by = \"Importance\", ascending = False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_importance.to_csv(\"../data/output/feat_importance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>failures</td>\n",
       "      <td>0.125524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>absences</td>\n",
       "      <td>0.065078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>school_MS</td>\n",
       "      <td>0.049090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>goout</td>\n",
       "      <td>0.048224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>age</td>\n",
       "      <td>0.045841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Walc</td>\n",
       "      <td>0.045117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>studytime</td>\n",
       "      <td>0.043758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Medu</td>\n",
       "      <td>0.041130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Fedu</td>\n",
       "      <td>0.039844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>higher_yes</td>\n",
       "      <td>0.038337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>freetime</td>\n",
       "      <td>0.036895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>health</td>\n",
       "      <td>0.036603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>famrel</td>\n",
       "      <td>0.036067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dalc</td>\n",
       "      <td>0.034117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>traveltime</td>\n",
       "      <td>0.025403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>address_U</td>\n",
       "      <td>0.021933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>sex_M</td>\n",
       "      <td>0.019625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>famsup_yes</td>\n",
       "      <td>0.017603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>schoolsup_yes</td>\n",
       "      <td>0.017509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>internet_yes</td>\n",
       "      <td>0.016496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>reason_other</td>\n",
       "      <td>0.015074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>activities_yes</td>\n",
       "      <td>0.013386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Fjob_teacher</td>\n",
       "      <td>0.013226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>nursery_yes</td>\n",
       "      <td>0.013190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>famsize_LE3</td>\n",
       "      <td>0.012665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>reason_home</td>\n",
       "      <td>0.012500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>reason_reputation</td>\n",
       "      <td>0.012477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Fjob_services</td>\n",
       "      <td>0.012354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Mjob_teacher</td>\n",
       "      <td>0.011972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>romantic_yes</td>\n",
       "      <td>0.011614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Fjob_other</td>\n",
       "      <td>0.010648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Mjob_other</td>\n",
       "      <td>0.010613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Mjob_services</td>\n",
       "      <td>0.009475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>guardian_mother</td>\n",
       "      <td>0.009046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Pstatus_T</td>\n",
       "      <td>0.008449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Mjob_health</td>\n",
       "      <td>0.006972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>paid_yes</td>\n",
       "      <td>0.005925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>guardian_other</td>\n",
       "      <td>0.004475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Fjob_health</td>\n",
       "      <td>0.001745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                index  Importance\n",
       "0            failures    0.125524\n",
       "1            absences    0.065078\n",
       "2           school_MS    0.049090\n",
       "3               goout    0.048224\n",
       "4                 age    0.045841\n",
       "5                Walc    0.045117\n",
       "6           studytime    0.043758\n",
       "7                Medu    0.041130\n",
       "8                Fedu    0.039844\n",
       "9          higher_yes    0.038337\n",
       "10           freetime    0.036895\n",
       "11             health    0.036603\n",
       "12             famrel    0.036067\n",
       "13               Dalc    0.034117\n",
       "14         traveltime    0.025403\n",
       "15          address_U    0.021933\n",
       "16              sex_M    0.019625\n",
       "17         famsup_yes    0.017603\n",
       "18      schoolsup_yes    0.017509\n",
       "19       internet_yes    0.016496\n",
       "20       reason_other    0.015074\n",
       "21     activities_yes    0.013386\n",
       "22       Fjob_teacher    0.013226\n",
       "23        nursery_yes    0.013190\n",
       "24        famsize_LE3    0.012665\n",
       "25        reason_home    0.012500\n",
       "26  reason_reputation    0.012477\n",
       "27      Fjob_services    0.012354\n",
       "28       Mjob_teacher    0.011972\n",
       "29       romantic_yes    0.011614\n",
       "30         Fjob_other    0.010648\n",
       "31         Mjob_other    0.010613\n",
       "32      Mjob_services    0.009475\n",
       "33    guardian_mother    0.009046\n",
       "34          Pstatus_T    0.008449\n",
       "35        Mjob_health    0.006972\n",
       "36           paid_yes    0.005925\n",
       "37     guardian_other    0.004475\n",
       "38        Fjob_health    0.001745"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/nipunbatra/50-ggplot-python/blob/master/Altair/DivergingLollipop.ipynb\n",
    "import altair as alt\n",
    "\n",
    "c1 = alt.Chart(feat_importance.head(5)).mark_bar(color='yellow', size = 5).encode(\n",
    "    y=alt.Y('index', sort=alt.EncodingSortField(order='descending', field='Importance'), title = None),\n",
    "    x=alt.X('Importance')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2 = alt.Chart(feat_importance.head(5)).mark_circle(color='yellow', size=400).encode(\n",
    "    y=alt.Y('index', sort=alt.EncodingSortField(order='descending', field='Importance')),\n",
    "    x=alt.X('Importance' ), \n",
    "    text='Importance'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "c3 = alt.Chart(feat_importance.head(5)).mark_text(color='black').encode(\n",
    "    y=alt.Y('index', sort=alt.EncodingSortField(order='descending', field='Importance')),\n",
    "    x=alt.X('Importance' ), \n",
    "    text='Importance'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.vegalite.v3+json": {
       "$schema": "https://vega.github.io/schema/vega-lite/v3.4.0.json",
       "config": {
        "mark": {
         "tooltip": null
        },
        "numberFormat": "0.4f",
        "view": {
         "height": 300,
         "width": 400
        }
       },
       "datasets": {
        "data-de1bbbe749c075def379b47d66e77338": [
         {
          "Importance": 0.1255243389974333,
          "index": "failures"
         },
         {
          "Importance": 0.06507835181977788,
          "index": "absences"
         },
         {
          "Importance": 0.04908963202750535,
          "index": "school_MS"
         },
         {
          "Importance": 0.04822369758238149,
          "index": "goout"
         },
         {
          "Importance": 0.04584115827638813,
          "index": "age"
         }
        ]
       },
       "height": 200,
       "layer": [
        {
         "data": {
          "name": "data-de1bbbe749c075def379b47d66e77338"
         },
         "encoding": {
          "x": {
           "field": "Importance",
           "type": "quantitative"
          },
          "y": {
           "field": "index",
           "sort": {
            "field": "Importance",
            "order": "descending"
           },
           "title": null,
           "type": "nominal"
          }
         },
         "mark": {
          "color": "yellow",
          "size": 5,
          "type": "bar"
         }
        },
        {
         "data": {
          "name": "data-de1bbbe749c075def379b47d66e77338"
         },
         "encoding": {
          "text": {
           "field": "Importance",
           "type": "quantitative"
          },
          "x": {
           "field": "Importance",
           "type": "quantitative"
          },
          "y": {
           "field": "index",
           "sort": {
            "field": "Importance",
            "order": "descending"
           },
           "type": "nominal"
          }
         },
         "mark": {
          "color": "yellow",
          "size": 400,
          "type": "circle"
         }
        },
        {
         "data": {
          "name": "data-de1bbbe749c075def379b47d66e77338"
         },
         "encoding": {
          "text": {
           "field": "Importance",
           "type": "quantitative"
          },
          "x": {
           "field": "Importance",
           "type": "quantitative"
          },
          "y": {
           "field": "index",
           "sort": {
            "field": "Importance",
            "order": "descending"
           },
           "type": "nominal"
          }
         },
         "mark": {
          "color": "black",
          "type": "text"
         }
        }
       ],
       "title": "Top 5 Features Ranked According to Importance (randomforest)",
       "width": 800
      },
      "image/png": "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",
      "text/plain": [
       "<VegaLite 3 object>\n",
       "\n",
       "If you see this message, it means the renderer has not been properly enabled\n",
       "for the frontend that you are using. For more information, see\n",
       "https://altair-viz.github.io/user_guide/troubleshooting.html\n"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chart = alt.layer(c1,c2,c3)\n",
    "chart.configure(\n",
    "    numberFormat=\"0.4f\"\n",
    ").properties(\n",
    "    title = \"Top 5 Features Ranked According to Importance (\"+list(test_rmse.head(1).index)[0]+\")\",\n",
    "    width = 800,\n",
    "    height = 200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart.save(\"../img/ranked_features.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
